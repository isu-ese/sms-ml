
@inproceedings{bettenburg_what_2008,
	title = {What makes a good bug report?},
	pages = {308--318},
	booktitle = {Proceedings of the 16th {ACM} {SIGSOFT} International Symposium on Foundations of software engineering},
	publisher = {{ACM}},
	author = {Bettenburg, Nicolas and Just, Sascha and Schröter, Adrian and Weiss, Cathrin and Premraj, Rahul and Zimmermann, Thomas},
	date = {2008},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/69P6IZPU/Bettenburg et al. - 2008 - What makes a good bug report.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/VW9QKCMZ/citation.html:text/html}
}

@inproceedings{bastani_synthesizing_2017,
	location = {Barcelona, Spain},
	title = {Synthesizing program input grammars},
	isbn = {978-1-4503-4988-8},
	url = {http://dl.acm.org/citation.cfm?doid=3062341.3062349},
	doi = {10.1145/3062341.3062349},
	abstract = {We present an algorithm for synthesizing a context-free grammar encoding the language of valid program inputs from a set of input examples and blackbox access to the program. Our algorithm addresses shortcomings of existing grammar inference algorithms, which both severely overgeneralize and are prohibitively slow. Our implementation, {GLADE}, leverages the grammar synthesized by our algorithm to fuzz test programs with structured inputs. We show that {GLADE} substantially increases the incremental coverage on valid inputs compared to two baseline fuzzers.},
	eventtitle = {the 38th {ACM} {SIGPLAN} Conference},
	pages = {95--110},
	booktitle = {Proceedings of the 38th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation  - {PLDI} 2017},
	publisher = {{ACM} Press},
	author = {Bastani, Osbert and Sharma, Rahul and Aiken, Alex and Liang, Percy},
	urldate = {2019-04-18},
	date = {2017},
	langid = {english},
	file = {Bastani et al. - 2017 - Synthesizing program input grammars.pdf:/home/rosettaroberts/Zotero/storage/RTMDXFT8/Bastani et al. - 2017 - Synthesizing program input grammars.pdf:application/pdf}
}

@article{klint_toward_2005,
	title = {Toward an engineering discipline for grammarware},
	volume = {14},
	issn = {1049331X},
	url = {http://portal.acm.org/citation.cfm?doid=1072997.1073000},
	doi = {10.1145/1072997.1073000},
	pages = {331--380},
	number = {3},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	author = {Klint, Paul and Lämmel, Ralf and Verhoef, Chris},
	urldate = {2019-04-18},
	date = {2005-07-01},
	langid = {english},
	file = {Klint et al. - 2005 - Toward an engineering discipline for grammarware.pdf:/home/rosettaroberts/Zotero/storage/R5CQWU7B/Klint et al. - 2005 - Toward an engineering discipline for grammarware.pdf:application/pdf}
}

@article{goloveshkin_tolerant_2018,
	title = {Tolerant parsing with a special kind of «Any» symbol: the algorithm and practical application},
	volume = {30},
	issn = {20798156, 22206426},
	url = {http://www.ispras.ru/en/proceedings/isp_30_2018_4/isp_30_2018_4_7/},
	doi = {10.15514/ISPRAS-2018-30(4)-1},
	shorttitle = {Tolerant parsing with a special kind of «Any» symbol},
	abstract = {Tolerant parsing is a form of syntax analysis aimed at capturing the structure of certain points of interest presented in a source code. While these points should be welldescribed in the corresponding language grammar, other parts of the program are allowed to be not presented in the grammar or to be described coarse-grained, thereby parser remains tolerant to the possible inconsistencies in the irrelevant area. Island grammars are one of the basic tolerant parsing techniques. “Island” is used as the relevant code alias, while the irrelevant code is called “water”. In the paper, a modified {LL}(1) parsing algorithm with built-in “Any” symbol processing is described. The “Any” symbol matches implicitly defined token sequences. The use of the algorithm for island grammars allows one to reduce irrelevant code description as well as to simplify patterns for relevant code matching. Our “Any” implementation is more accurate and less restrictive in comparison with the closest analogues implemented in Coco/R and {LightParse} parser generators. It also has potentially lower overhead than the “bounded seas” concept implemented in {PetitParser}. As shown in the experimental section, the tolerant parser generated by the C\# island grammar is proven to be applicable for large-scale software projects analysis.},
	pages = {7--28},
	number = {4},
	journaltitle = {Proceedings of the Institute for System Programming of the {RAS}},
	author = {Goloveshkin, A.V. and Mikhalkovich, S.S.},
	urldate = {2019-04-19},
	date = {2018},
	langid = {english},
	file = {SFU, Rostov-on-Don, Russia et al. - 2018 - Tolerant parsing with a special kind of «Any» symb.pdf:/home/rosettaroberts/Zotero/storage/BL72465M/SFU, Rostov-on-Don, Russia et al. - 2018 - Tolerant parsing with a special kind of «Any» symb.pdf:application/pdf}
}

@article{shang_taming_2008,
	title = {Taming verification hardness: an efficient algorithm for testing subgraph isomorphism},
	volume = {1},
	shorttitle = {Taming verification hardness},
	pages = {364--375},
	number = {1},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	author = {Shang, Haichuan and Zhang, Ying and Lin, Xuemin and Yu, Jeffrey Xu},
	date = {2008},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/Q3LF2EF4/Shang et al. - 2008 - Taming verification hardness an efficient algorit.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/3MG7BSLN/citation.html:text/html}
}

@inproceedings{synytskyy_robust_2003,
	title = {Robust multilingual parsing using island grammars},
	pages = {266--278},
	booktitle = {Proceedings of the 2003 conference of the Centre for Advanced Studies on Collaborative research},
	publisher = {{IBM} Press},
	author = {Synytskyy, Nikita and Cordy, James R. and Dean, Thomas R.},
	date = {2003},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/XHC7TP7D/Synytskyy et al. - 2003 - Robust multilingual parsing using island grammars.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/45F3DFMF/citation.html:text/html}
}

@article{mushtaq_multilingual_2017,
	title = {Multilingual source code analysis: A systematic literature review},
	volume = {5},
	shorttitle = {Multilingual source code analysis},
	pages = {11307--11336},
	journaltitle = {{IEEE} Access},
	author = {Mushtaq, Zaigham and Rasool, Ghulam and Shehzad, Balawal},
	date = {2017},
	file = {Snapshot:/home/rosettaroberts/Zotero/storage/6ECPCELF/7953501.html:text/html}
}

@article{grindley_identification_1993,
	title = {Identification of tertiary structure resemblance in proteins using a maximal common subgraph isomorphism algorithm},
	volume = {229},
	pages = {707--721},
	number = {3},
	journaltitle = {Journal of molecular biology},
	author = {Grindley, Helen M. and Artymiuk, Peter J. and Rice, David W. and Willett, Peter},
	date = {1993},
	file = {Snapshot:/home/rosettaroberts/Zotero/storage/C4SEFYTN/S0022283683710740.html:text/html}
}

@inproceedings{bacchelli_extracting_2011,
	title = {Extracting structured data from natural language documents with island parsing},
	pages = {476--479},
	booktitle = {Automated Software Engineering ({ASE}), 2011 26th {IEEE}/{ACM} International Conference on},
	publisher = {{IEEE}},
	author = {Bacchelli, Alberto and Cleve, Anthony and Lanza, Michele and Mocci, Andrea},
	date = {2011},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/PMUGZSXY/Bacchelli et al. - 2011 - Extracting structured data from natural language d.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/W9XP9HUD/6100103.html:text/html}
}

@inproceedings{strein_cross-language_2006,
	title = {Cross-language program analysis and refactoring},
	pages = {207--216},
	booktitle = {2006 Sixth {IEEE} International Workshop on Source Code Analysis and Manipulation},
	publisher = {{IEEE}},
	author = {Strein, Dennis and Kratz, Hans and Lowe, Welf},
	date = {2006},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/RBCU5HUQ/Strein et al. - 2006 - Cross-language program analysis and refactoring.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/NFQSNL6F/4026870.html:text/html}
}

@book{reinhard_wilhelm_compiler_1995,
	location = {Boston, United States},
	title = {Compiler Design},
	isbn = {0-201-42290-5},
	pagetotal = {606},
	publisher = {Addison-Wesley},
	author = {Reinhard Wilhelm, Dieter Maurer},
	date = {1995-01-01}
}

@inproceedings{deursen_building_1999,
	title = {Building documentation generators},
	doi = {10.1109/ICSM.1999.792497},
	abstract = {In order to maintain the consistency between sources and documentation, while at the same time providing documentation at the design level, it is necessary to generate documentation from sources in such a way that it can be integrated with hand-written documentation. In order to simplify the construction of documentation generators, we introduce island grammars, which only define those syntactic structures needed for (re)documentation purposes. We explain how they can be used to obtain various forms of documentation, such as data dependency diagrams for mainframe batch jobs. Moreover, we discuss how the derived information can be made available via a hypertext structure. We conclude with an industrial case study in which a 600,000 {LOC} {COBOL} legacy system is redocumented using the techniques presented in the paper.},
	eventtitle = {Proceedings {IEEE} International Conference on Software Maintenance - 1999 ({ICSM}'99). 'Software Maintenance for Business Change' (Cat. No.99CB36360)},
	pages = {40--49},
	booktitle = {Proceedings {IEEE} International Conference on Software Maintenance - 1999 ({ICSM}'99). 'Software Maintenance for Business Change' (Cat. No.99CB36360)},
	author = {Deursen, A. Van and Kuipers, T.},
	date = {1999-08},
	keywords = {grammars, island grammars, 600,000 {LOC} {COBOL} legacy system, Cost function, data dependency diagrams, design level, Documentation, documentation generators, hand-written documentation, hypermedia, hypertext structure, Lab-on-a-chip, mainframe batch jobs, Outsourcing, Read only memory, redocumentation, syntactic structures, system documentation},
	file = {IEEE Xplore Abstract Record:/home/rosettaroberts/Zotero/storage/YER64GRN/792497.html:text/html;Submitted Version:/home/rosettaroberts/Zotero/storage/R2BMQH8K/Deursen and Kuipers - 1999 - Building documentation generators.pdf:application/pdf}
}

@article{ullmann_algorithm_1976,
	title = {An algorithm for subgraph isomorphism},
	volume = {23},
	pages = {31--42},
	number = {1},
	journaltitle = {Journal of the {ACM} ({JACM})},
	author = {Ullmann, Julian R.},
	date = {1976},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/NLZT4HNG/Ullmann - 1976 - An algorithm for subgraph isomorphism.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/XFGZ3G6Q/citation.html:text/html}
}

@article{messmer_new_1998,
	title = {A new algorithm for error-tolerant subgraph isomorphism detection},
	volume = {20},
	pages = {493--504},
	number = {5},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Messmer, Bruno T. and Bunke, Horst},
	date = {1998},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/U95HMCD3/login.html:text/html;Snapshot:/home/rosettaroberts/Zotero/storage/3UUD2J7E/682179.html:text/html}
}

@inproceedings{bunke_comparison_2002,
	title = {A comparison of algorithms for maximum common subgraph on randomly connected graphs},
	pages = {123--132},
	booktitle = {Joint {IAPR} International Workshops on Statistical Techniques in Pattern Recognition ({SPR}) and Structural and Syntactic Pattern Recognition ({SSPR})},
	publisher = {Springer},
	author = {Bunke, Horst and Foggia, Pasquale and Guidobaldi, Corrado and Sansone, Carlo and Vento, Mario},
	date = {2002},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/CUCLS6S4/Bunke et al. - 2002 - A comparison of algorithms for maximum common subg.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/HA46DUSM/10.html:text/html}
}

@article{cordella_sub_2004,
	title = {A (sub) graph isomorphism algorithm for matching large graphs},
	volume = {26},
	pages = {1367--1372},
	number = {10},
	journaltitle = {{IEEE} transactions on pattern analysis and machine intelligence},
	author = {Cordella, Luigi P. and Foggia, Pasquale and Sansone, Carlo and Vento, Mario},
	date = {2004},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/IVLLX2RR/Cordella et al. - 2004 - A (sub) graph isomorphism algorithm for matching l.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/K2NFRBUD/1323804.html:text/html}
}

@incollection{eppstein_subgraph_2002,
	title = {Subgraph isomorphism in planar graphs and related problems},
	pages = {283--309},
	booktitle = {Graph Algorithms And Applications I},
	publisher = {World Scientific},
	author = {Eppstein, David},
	date = {2002},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/HD5NN6I4/Eppstein - 2002 - Subgraph isomorphism in planar graphs and related .pdf:application/pdf}
}

@inproceedings{moonen_lightweight_2002,
	title = {Lightweight Impact Analysis using Island Grammars.},
	pages = {219--228},
	booktitle = {{IWPC}},
	publisher = {Citeseer},
	author = {Moonen, Leon},
	date = {2002},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/RTH5Q3U9/Moonen - 2002 - Lightweight Impact Analysis using Island Grammars..pdf:application/pdf}
}

@book{haoxiang_languages_1988,
	location = {Boston, {MA}, {USA}},
	edition = {3rd},
	title = {Languages and Machines An Introduction to the Theory of Computer Science},
	isbn = {0-201-15768-3},
	abstract = {Preface The objective of the third edition of Languages and Machines: An Introduction to the Theory of Computer Science remains the same as that of the first two editions, to provide a mathematically sound presentation of the theory of computer},
	publisher = {Addison-Wesley Longman Publishing Co. Inc.},
	author = {Haoxiang, Ma},
	date = {1988},
	langid = {english},
	file = {Snapshot:/home/rosettaroberts/Zotero/storage/43FAYXNN/Languages_and_Machines_An_Introduction_to_the_Theory_of_Computer_Science.html:text/html}
}

@inproceedings{moonen_generating_2001,
	title = {Generating robust parsers using island grammars},
	doi = {10.1109/WCRE.2001.957806},
	abstract = {Source model extraction, the automated extraction of information from system artifacts, is a common phase in reverse engineering tools. One of the major challenges of this phase is creating extractors that can deal with irregularities in the artifacts that are typical for the reverse engineering domain (for example, syntactic errors, incomplete source code, language dialects and embedded languages). The paper proposes a solution in the form of island grammars, a special kind of grammar that combines the detailed specification possibilities of grammars with the liberal behavior of lexical approaches. We show how island grammars can be used to generate robust parsers that combine the accuracy of syntactical analysis with the speed, flexibility and tolerance usually only found in lexical analysis. We conclude with a discussion of the development of {MANGROVE}, a generator for source model extractors based on island grammars and describe its application to a number of case studies.},
	eventtitle = {Proceedings Eighth Working Conference on Reverse Engineering},
	pages = {13--22},
	booktitle = {Proceedings Eighth Working Conference on Reverse Engineering},
	author = {Moonen, L.},
	date = {2001-10},
	keywords = {Application software, automated information extraction, case studies, computational linguistics, Computer languages, Data mining, detailed specification, embedded languages, fuzzy parsing, grammars, incomplete source code, island grammars, language dialects, lexical approaches, Libraries, Maintenance engineering, {MANGROVE}, Mars, parser generation, partial parsing, program analysis, program compilers, reverse engineering, Reverse engineering, reverse engineering domain, reverse engineering tools, robust parser generation, robust parsers, Robustness, Software maintenance, source model extraction, source model extractors, syntactic errors, syntactical analysis, system artifacts, Transaction databases},
	file = {IEEE Xplore Abstract Record:/home/rosettaroberts/Zotero/storage/F767EEMY/957806.html:text/html;IEEE Xplore Full Text PDF:/home/rosettaroberts/Zotero/storage/HVVDIHDJ/Moonen - 2001 - Generating robust parsers using island grammars.pdf:application/pdf}
}

@book{ghezzi_fundamentals_2002,
	location = {Upper Saddle River, {NJ}, {USA}},
	edition = {2nd},
	title = {Fundamentals of Software Engineering},
	isbn = {978-0-13-305699-0},
	abstract = {From the Publisher:This book provides selective, in-depth coverage of the fundamentals of software engineering by stressing principles and methods through rigorous formal and informal approaches. In contrast to other books which are based on the lifecycle model of software development, the authors emphasize identifying and applying fundamental principles that are applicable throughout the software lifecycle. This emphasis enables readers to respond to the rapid changes in technology that are common today. Principles and techniques are emphasized rather than specific tools—users learn why particular techniques should or should not be used. Understanding the principles and techniques on which tools are based makes mastering a variety of specific tools easier. The authors discuss principles such as design, specification, verification, production, management and tools. Now coverage includes: more detailed analysis and explanation of object-oriented techniques; the use of Unified Modeling Language ({UML}); requirements analysis and software architecture; Model checking—a technique that provides automatic support to the human activity of software verification; {GQM}—used to evaluate software quality and help improve the software process; Z specification language. For software engineers.},
	publisher = {Prentice Hall {PTR}},
	author = {Ghezzi, Carlo and Jazayeri, Mehdi and Mandrioli, Dino},
	date = {2002}
}

@inproceedings{kuramochi_frequent_2001,
	title = {Frequent subgraph discovery},
	pages = {313--320},
	booktitle = {Data Mining, 2001. {ICDM} 2001, Proceedings {IEEE} international conference on},
	publisher = {{IEEE}},
	author = {Kuramochi, Michihiro and Karypis, George},
	date = {2001},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/FRLU9FTD/Kuramochi and Karypis - 2001 - Frequent subgraph discovery.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/TULKIHWA/989534.html:text/html}
}

@inproceedings{huan_efficient_2003,
	title = {Efficient mining of frequent subgraphs in the presence of isomorphism},
	pages = {549},
	booktitle = {null},
	publisher = {{IEEE}},
	author = {Huan, Jun and Wang, Wei and Prins, Jan},
	date = {2003},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/WINPSKMB/Huan et al. - 2003 - Efficient mining of frequent subgraphs in the pres.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/L4YQ8NQI/19780549.html:text/html}
}

@inproceedings{klusener_deriving_2003,
	title = {Deriving tolerant grammars from a base-line grammar},
	pages = {179--188},
	booktitle = {Software Maintenance, 2003. {ICSM} 2003. Proceedings. International Conference on},
	publisher = {{IEEE}},
	author = {Klusener, Steven and Lammel, Ralf},
	date = {2003},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/UFACT5SD/Klusener and Lammel - 2003 - Deriving tolerant grammars from a base-line gramma.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/NY4WTEIW/1235420.html:text/html}
}

@article{kurs_bounded_2015,
	title = {Bounded seas},
	volume = {44},
	pages = {114--140},
	journaltitle = {Computer languages, systems \& structures},
	author = {Kurš, Jan and Lungu, Mircea and Iyadurai, Rathesan and Nierstrasz, Oscar},
	date = {2015},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/RTWVIN2X/Kurš et al. - 2015 - Bounded seas.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/2MGNZCVB/S1477842415000536.html:text/html}
}

@inproceedings{collard_xml-based_2003,
	title = {An {XML}-based lightweight C++ fact extractor},
	pages = {134--143},
	booktitle = {Program Comprehension, 2003. 11th {IEEE} International Workshop on},
	publisher = {{IEEE}},
	author = {Collard, Michael L. and Kagdi, Huzefa H. and Maletic, Jonathan I.},
	date = {2003},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/VY4I8RQI/Collard et al. - 2003 - An XML-based lightweight C++ fact extractor.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/2V6ZIF2D/1199197.html:text/html}
}

@inproceedings{carroll_island_1983,
	title = {An island parsing interpreter for the full augmented transition network formalism},
	pages = {101--105},
	booktitle = {Proceedings of the first conference on European chapter of the Association for Computational Linguistics},
	publisher = {Association for Computational Linguistics},
	author = {Carroll, John A.},
	date = {1983},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/8GKZ2GSB/Carroll - 1983 - An island parsing interpreter for the full augment.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/SA95XNYC/citation.html:text/html}
}

@report{carroll_island_1982,
	title = {An island parsing interpreter for Augmented Transition Networks},
	url = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-33.html},
	number = {{UCAM}-{CL}-{TR}-33},
	institution = {University of Cambridge, Computer Laboratory},
	author = {Carroll, John A.},
	urldate = {2019-02-03},
	date = {1982},
	langid = {english},
	file = {Full Text PDF:/home/rosettaroberts/Zotero/storage/NZ5MP4I9/Carroll - 1982 - An island parsing interpreter for Augmented Transi.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/EVDPU549/UCAM-CL-TR-33.html:text/html}
}

@inproceedings{lischka_virtual_2009,
	title = {A virtual network mapping algorithm based on subgraph isomorphism detection},
	pages = {81--88},
	booktitle = {Proceedings of the 1st {ACM} workshop on Virtualized infrastructure systems and architectures},
	publisher = {{ACM}},
	author = {Lischka, Jens and Karl, Holger},
	date = {2009},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/8WZMGX2N/Lischka and Karl - 2009 - A virtual network mapping algorithm based on subgr.pdf:application/pdf;Snapshot:/home/rosettaroberts/Zotero/storage/G2MDMCZ3/citation.html:text/html}
}

@article{tomita_worst-case_2006,
	title = {The worst-case time complexity for generating all maximal cliques and computational experiments},
	volume = {363},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397506003586},
	doi = {10.1016/j.tcs.2006.06.015},
	series = {Computing and Combinatorics},
	abstract = {We present a depth-first search algorithm for generating all maximal cliques of an undirected graph, in which pruning methods are employed as in the Bron–Kerbosch algorithm. All the maximal cliques generated are output in a tree-like form. Subsequently, we prove that its worst-case time complexity is O(3n/3) for an n-vertex graph. This is optimal as a function of n, since there exist up to 3n/3 maximal cliques in an n-vertex graph. The algorithm is also demonstrated to run very fast in practice by computational experiments.},
	pages = {28--42},
	number = {1},
	journaltitle = {Theoretical Computer Science},
	shortjournal = {Theoretical Computer Science},
	author = {Tomita, Etsuji and Tanaka, Akira and Takahashi, Haruhisa},
	urldate = {2019-05-09},
	date = {2006-10-25},
	keywords = {Computational experiments, Enumeration, Maximal cliques, Worst-case time complexity},
	file = {ScienceDirect Full Text PDF:/home/rosettaroberts/Zotero/storage/GD8CK37I/Tomita et al. - 2006 - The worst-case time complexity for generating all .pdf:application/pdf;ScienceDirect Snapshot:/home/rosettaroberts/Zotero/storage/DSFQQ4WR/S0304397506003586.html:text/html}
}

@article{raymond_maximum_nodate,
	title = {Maximum common subgraph isomorphism algorithms for the matching of chemical structures},
	abstract = {The maximum common subgraph ({MCS}) problem has become increasingly important in those aspects of chemoinformatics that involve the matching of 2D or 3D chemical structures. This paper provides a classiﬁcation and a review of the many {MCS} algorithms, both exact and approximate, that have been described in the literature, and makes recommendations regarding their applicability to typical chemoinformatics tasks.},
	pages = {13},
	author = {Raymond, John W and Willett, Peter},
	langid = {english},
	file = {Raymond and Willett - Maximum common subgraph isomorphism algorithms for.pdf:/home/rosettaroberts/Zotero/storage/JFM6B5X6/Raymond and Willett - Maximum common subgraph isomorphism algorithms for.pdf:application/pdf}
}

@inproceedings{conte_comparison_2003,
	location = {Berlin, Heidelberg},
	title = {A Comparison of Three Maximum Common Subgraph Algorithms on a Large Database of Labeled Graphs},
	isbn = {978-3-540-40452-1},
	url = {http://dl.acm.org/citation.cfm?id=1757868.1757884},
	series = {{GbRPR}'03},
	abstract = {A graph g is called a maximum common subgraph of two graphs, g1 and g2, if there exists no other common subgraph of g1 and g2 that has more nodes than g. For the maximum common subgraph problem, exact and inexact algorithms are known from the literature. Nevertheless, until now no effort has been done for characterizing their performance, mainly for the lack of a large database of graphs. In this paper, three exact and well-known algorithms for maximum common subgraph detection are described. Moreover, a large database containing various categories of pairs of graphs (e.g. randomly connected graphs, meshes, bounded valence graphs...), having a maximum common subgraph of at least two nodes, is presented, and the performance of the three algorithms is evaluated on this database.},
	pages = {130--141},
	booktitle = {Proceedings of the 4th {IAPR} International Conference on Graph Based Representations in Pattern Recognition},
	publisher = {Springer-Verlag},
	author = {Conte, D. and Guidobaldi, C. and Sansone, C.},
	urldate = {2019-05-10},
	date = {2003},
	note = {event-place: York, {UK}}
}

@article{conte_challenging_2007,
	title = {Challenging Complexity of Maximum Common Subgraph Detection Algorithms: A Performance Analysis of Three Algorithms on a Wide Database of Graphs},
	volume = {11},
	doi = {10.7155/jgaa.00139},
	shorttitle = {Challenging Complexity of Maximum Common Subgraph Detection Algorithms},
	abstract = {Graphs are an extremely general and powerful data structure. In pattern recognition and computer vision, graphs are used to represent patterns to be recognized or classified. Detection of maximum common subgraph ({MCS}) is useful for matching, comparing and evaluate the similarity of patterns. {MCS} is a well known {NP}-complete problem for which optimal and suboptimal algorithms are known from the literature. Nevertheless, until now no effort has been done for characterizing their performance. The lack of a large database of graphs makes the task of comparing the performance of different graph matching algorithms difficult, and often the selection of an algorithm is made on the basis of a few experimental results available. In this paper, three optimal and well-known algorithms for maximum common subgraph detection are described. Moreover a large database containing various categories of pairs of graphs (e.g. random graphs, meshes, bounded valence graphs), is presented, and the performance of the three algorithms is evaluated on this database. Article Type Communicated by Submitted Revised Regular Paper U. Brandes September 2005 January 2007 D. Conte et al., Maximum Common Subgraph, {JGAA}, 11(1) 99–143 (2007) 100},
	pages = {99--143},
	journaltitle = {J. Graph Algorithms Appl.},
	author = {Conte, Donatello and Foggia, Pasquale and Vento, Mario},
	date = {2007},
	keywords = {Algorithm, Computer vision, Data structure, Graph (discrete mathematics), Journal of Graph Algorithms and Applications, Matching (graph theory), {NP}-completeness, Pattern recognition, Random graph},
	file = {Full Text PDF:/home/rosettaroberts/Zotero/storage/J5G7JFXE/Conte et al. - 2007 - Challenging Complexity of Maximum Common Subgraph .pdf:application/pdf}
}

@inproceedings{welling_performance_2011,
	title = {A Performance Analysis on Maximal Common Subgraph Algorithms},
	abstract = {Graphs can be used as a tool to determine similarity between structured objects. The maximal common subgraph of two graphs G and H is the largest graph in terms of edges that is isomorphic to a subgraph of G and H. Finding the maximal common subgraph is an {NP}-complete problem. It is useful in many areas like (bio)chemistry, file versioning and artificial intelligence. There are many papers that evaluate algorithms for finding maximal common induced subgraphs, but little research has been done on the maximal common subgraph that is not an induced subgraph. We have implemented and benchmarked two maximal common (not induced) subgraph algorithms: a backtrack search algorithm ({McGregor}), and an algorithm that transforms the maximal common subgraph problem to the largest clique problem (Koch). We created generators for randomly connected and mesh structured graphs, these generators have been used to create a database of graph pairs to benchmark the two algorithms. The results of our benchmark have shown that in most cases Koch is more efficient, because after creating the edge product graph needed for the clique detection. The actual clique detection is a relatively simple search.},
	author = {Welling, Ruud},
	date = {2011},
	keywords = {Artificial intelligence, Backtracking, Benchmark (computing), Clique (graph theory), Clique problem, Graph - visual representation, Induced subgraph, Koch snowflake, Maximal set, Paper, Randomness, Search algorithm},
	file = {Full Text PDF:/home/rosettaroberts/Zotero/storage/W6DZM6J7/Welling - 2011 - A Performance Analysis on Maximal Common Subgraph .pdf:application/pdf}
}

@online{noauthor_title:_nodate,
	title = {Title:},
	url = {http://www.cs.kent.edu/~jbaker/paper/},
	urldate = {2019-05-16},
	file = {Title\::/home/rosettaroberts/Zotero/storage/CW3IUUF4/paper.html:text/html}
}

@article{durand_efficient_1999,
	title = {An efficient algorithm for similarity analysis of molecules},
	volume = {2},
	pages = {1--16},
	number = {17},
	journaltitle = {Internet Journal of Chemistry},
	author = {Durand, Paul J. and Pasari, Rohit and Baker, Johnnie W. and Tsai, Chun-che},
	date = {1999},
	file = {Full Text:/home/rosettaroberts/Zotero/storage/EP988BBA/paper.html:text/html}
}